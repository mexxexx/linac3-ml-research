<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Max Mihailescu" />
  <title>Ideas for the Linac3 Source ML Analysis</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>

  /*
  * I add this to html files generated with pandoc.
  * Taken from https://gist.github.com/killercup/5917178 and modified.
  */


  /* Basic page elements */

   html {
      font-size: 100%;
      overflow-y: scroll;
      -webkit-text-size-adjust: 100%;
      -ms-text-size-adjust: 100%;
    }
    
    body {
      color: #444;
      font-family: Georgia, Palatino, 'Palatino Linotype', Times, 'Times New Roman', serif;
      font-size: 12px;
      line-height: 1.7;
      padding: 1em;
      margin: auto;
      max-width: 42em;
      background: #fefefe;
    }
    
    a {
      color: #0645ad;
      text-decoration: none;
    }
    
    a:visited {
      color: #0b0080;
    }
    
    a:hover {
      color: #06e;
    }
    
    a:active {
      color: #faa700;
    }
    
    a:focus {
      outline: thin dotted;
    }
    
    *::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
    }
    
    *::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
    }
    
    a::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
    }
    
    a::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
    }
    
    p {
      text-align: justify;
      margin: 1em 0;
    }
    
    img {
      max-width: 100%;
    }
    
    h1, h2, h3, h4, h5, h6 {
      color: #111;
      line-height: 125%;
      margin-top: 2em;
      font-weight: normal;
    }
    
    h4, h5, h6 {
      font-weight: bold;
    }
    
    h1 {
      font-size: 2.5em;
    }
    
    h2 {
      font-size: 2em;
    }
    
    h3 {
      font-size: 1.5em;
    }
    
    h4 {
      font-size: 1.2em;
    }
    
    h5 {
      font-size: 1em;
    }
    
    h6 {
      font-size: 0.9em;
    }
    
    blockquote {
      color: #666666;
      margin: 0;
      padding-left: 3em;
      border-left: 0.5em #EEE solid;
    }
    
    hr {
      display: block;
      height: 2px;
      border: 0;
      border-top: 1px solid #aaa;
      border-bottom: 1px solid #eee;
      margin: 1em 0;
      padding: 0;
    }
    
    pre, code, kbd, samp {
      color: #000;
      font-family: monospace, monospace;
      _font-family: 'courier new', monospace;
      font-size: 0.98em;
    }
    
    pre {
      white-space: pre;
      white-space: pre-wrap;
      word-wrap: break-word;
    }
    
    b, strong {
      font-weight: bold;
    }
    
    dfn {
      font-style: italic;
    }
    
    ins {
      background: #ff9;
      color: #000;
      text-decoration: none;
    }
    
    mark {
      background: #ff0;
      color: #000;
      font-style: italic;
      font-weight: bold;
    }
    
    sub, sup {
      font-size: 75%;
      line-height: 0;
      position: relative;
      vertical-align: baseline;
    }
    
    sup {
      top: -0.5em;
    }
    
    sub {
      bottom: -0.25em;
    }
    
    ul, ol {
      margin: 1em 0;
      padding: 0 0 0 2em;
    }
    
    li p:last-child {
      margin-bottom: 0;
    }
    
    ul ul, ol ol {
      margin: .3em 0;
    }
    
    dl {
      margin-bottom: 1em;
    }
    
    dt {
      font-weight: bold;
      margin-bottom: .8em;
    }
    
    dd {
      margin: 0 0 .8em 2em;
    }
    
    dd:last-child {
      margin-bottom: 0;
    }
    
    img {
      border: 0;
      -ms-interpolation-mode: bicubic;
      vertical-align: middle;
    }
    
    /* Figure */
    figure {
      display: block;
      text-align: center;
      margin: 1em 0 3em;
    }
    
    figure img {
      border: none;
      margin: 0 auto;
    }
    
    figure figcaption {
      text-align: center;
      font-size: 90%;
      font-style: italic;
      margin: 0 0 .8em;
    }
    
    table {
      margin-bottom: 2em;
      border-bottom: 1px solid #ddd;
      border-right: 1px solid #ddd;
      border-spacing: 0;
      border-collapse: collapse;
    }
    
    table th {
      padding: .2em 1em;
      background-color: #eee;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
    }
    
    table td {
      padding: .2em 1em;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
      vertical-align: top;
    }

    /* Tags */
    .tags {
      font-size: 90%;
      margin-top: 2em;
      list-style-type: none;
      overflow: hidden;
      padding: 0;
      overflow: hidden;
      text-align: center;
    }

    .tags li {
      float: left;
      padding: 2px 15px;
      background-color: #d6eaff;
      margin: auto 10px;
      border-radius: 15px;
    }

    /* Navigation menu */
    nav#menu {
      top: 0;
      width: 100%;
      margin-bottom: -2em;
      padding-bottom: 0.5em;
      border-bottom: 1px solid #dedede;
    }

    nav#menu ul {
      list-style-type: none;
      margin: 0;
      padding: 0;
      overflow: hidden;
    }
    
    nav#menu li {
      float: left;
    }

    nav#menu li:first-child {
      margin-left: -16px;
    }
    
    nav#menu li a {
      font-size: 1.5em;
      color: #111;
      display: block;
      padding: 14px 16px;
      outline: none;
    
      position: relative;
    }
    
    nav#menu li a:after {
      content: "";
      position: absolute;
      border-top: 2px solid #555;
      left: 30%;
      bottom: 10px;
      width: 40%;
    }
    
    nav#menu li a:hover:not(.active):after {
      border-top: 2px solid #999;
    }
    
    nav#menu li a.active:after {
      border-top: 2px solid #ba331e;
    }
    
    nav#menu li a:hover.active:after {
      border-top: 2px solid #ff573d;
    }
    
    /* Header */
    header {
    }

    header .title {
    }

    header .date {
      margin-top: -1.5em;
      font-style: italic;
    }

    header .author {
      font-size: 1.2em;
    }
    
    /* Footer */
    footer {
      margin-top: 2em;
    }

    footer p {
      text-align: center;
      font-size: 80%;
    }

    footer hr {
      border: 0;
      border-bottom: 1px solid #dedede;
      max-width: 70%;
      margin: 0 auto;
    }

    /* Blog entries */
    div#blog_posts {
    }

    section.blog_post_preview {
      margin-bottom: 2em;
    }

    section.blog_post_preview h2 {
      margin-top: 1em;
    }

    section.blog_post_preview .date {
      margin-top: -1.5em;
      font-style: italic;
    }

    /* Blog navigation */
    nav#blog_preview_page_number {
      margin-top: 2em;
      display: flex;
      justify-content: center;
      text-align: center;
    }

    nav#blog_preview_page_number #blog_preview_page_number_prev {
      width: 50px;
    }

    nav#blog_preview_page_number #blog_preview_page_number_current {
      width: 50px;
    }

    nav#blog_preview_page_number #blog_preview_page_number_next {
      width: 50px;
    }

    /*nav#blog_preview_page_number .prev_blog_page {
      visibility: hidden;
    }

    nav#blog_preview_page_number .prev_blog_page:after {
      visibility: visible;
      content: "Previous";
    }

    nav#blog_preview_page_number .next_blog_page {
      visibility: hidden;
    }

    nav#blog_preview_page_number .next_blog_page:after {
      visibility: visible;
      content: "Next";
    }*/


    
    @media only screen and (min-width: 480px) {
      body {
        font-size: 14px;
      }
    }
    @media only screen and (min-width: 768px) {
      body {
        font-size: 16px;
      }
    }
    @media print {
      * {
        background: transparent !important;
        color: black !important;
        filter: none !important;
        -ms-filter: none !important;
      }
    
      body {
        font-size: 12pt;
        max-width: 100%;
      }
    
      a, a:visited {
        text-decoration: underline;
      }
    
      hr {
        height: 1px;
        border: 0;
        border-bottom: 1px solid black;
      }
    
      a[href]:after {
        content: " (" attr(href) ")";
      }
    
      abbr[title]:after {
        content: " (" attr(title) ")";
      }
    
      .ir a:after, a[href^="javascript:"]:after, a[href^="#"]:after {
        content: "";
      }
    
      pre, blockquote {
        border: 1px solid #999;
        padding-right: 1em;
        page-break-inside: avoid;
      }
    
      tr, img {
        page-break-inside: avoid;
      }
    
      img {
        max-width: 100% !important;
      }
    
      @page :left {
        margin: 15mm 20mm 15mm 10mm;
    }
    
      @page :right {
        margin: 15mm 10mm 15mm 20mm;
    }
    
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
    
      h2, h3 {
        page-break-after: avoid;
      }
    }

  </style>
</head>
<body>
<header id="title-block-header">
<h1 class="title">Ideas for the Linac3 Source ML Analysis</h1>
<p class="author">Max Mihailescu</p>
</header>
<p>This document provides a collection of ideas and topics for the analysis of the Linac3 Ion Source from a ML viewpoint. I will try to collect descriptions and links to interesting papers and summarize the results I had when trying out some of them.</p>
<h2 id="clustering">Clustering</h2>
<p>Given a collection of data points, clustering is to group together points that are similar under some kind of similarity metric. Usually, this is an unsupervised technique, meaning that no reference labels are known. There exist a variety of different algorithms, and each algorithm can produce very different results on the same set of data. Therefore it is crucial to somehow evaluate the results.</p>
<p>For Linac3 we performed a Clustering Analysis with the goal, to see, if certain settings of the source would lead to a stable beam current. For the resulting report please contact Detlef Küchler (CERN BE-ABP-HSL).</p>
<p>The clustering algorithm we used is called <em>Optigrid</em> and is described in the paper “Optimal Grid-Clustering: Towards Breaking the Curse of Dimensionality in High-Dimensional Clustering” by Alexander Hinneburg and Daniel A. Keim. <span class="citation" data-cites="Hinneburg:OptimalGridClustering">(Hinneburg and Keim 1999)</span></p>
<h2 id="matrix-profile">Matrix Profile</h2>
<p>The Matrix Profile is a tool for efficient motif discovery in time series, i.e. for discovery of repeated or “conserved” patterns. It can also be used to find time series discords, i.e. anomalies. A large number of papers was published by the same working group, you can find the projects website here <span class="citation" data-cites="Keogh:UCRMatrixProfile">(Keogh, n.d.)</span>. For a good introduction with example applications read the first paper <span class="citation" data-cites="Yeh:MatrixProfileI">(Yeh et al. 2016)</span>.</p>
<h3 id="what-is-the-matrix-profile">What is the Matrix Profile?</h3>
<p>First, let’s understand what a subsequence is. Consider a time series <span class="math inline">\(T=T_1 \dots T_n,\quad T_i\in\mathbb{R}\)</span> of length <span class="math inline">\(n\)</span>, and fix a number <span class="math inline">\(m &lt; n\)</span> (typically <span class="math inline">\(m \ll n\)</span>). Now, a subsequence of length <span class="math inline">\(m\)</span> starting at <span class="math inline">\(i\)</span> is the continuous block <span class="math inline">\(T_i \dots T_{i+m}\)</span>. By sliding a window of size <span class="math inline">\(m\)</span> over <span class="math inline">\(T\)</span> we can get all <span class="math inline">\(n-m+1\)</span> subsequences of length <span class="math inline">\(m\)</span>.</p>
<p>Now, we can define the distance between two subsequences. The most obvious choice is the euclidean distance <span class="math inline">\(dist(Q, T) = \sqrt{\left(Q_1 - T_1\right)^2+\dots+\left(Q_m-T_m\right)^2}\)</span>. However, for the matrix profile we work with the so called <em>z-normalized</em> euclidean distance. It is the euclidean distance of the z-normalized subsequences, i.e. we subtract the mean of the subsequence and divide the difference by its standard deviation, and only then take the elidean distance. By this we rescale all subsequences to make them more compareable. Note that under some circumstances this might be undesirable, for example when search for motifs in the call of a bird where the pitch could be relevant, and not only the shape of a signal.</p>
<p>The Matrix Profile <span class="math inline">\(P\)</span> is a meta time series, that for every subsequence stores the smallest distance to some other subsequence. Furthermore, the Matrix Profile Indices <span class="math inline">\(I\)</span> is another meta time series, that for every subsequence stores the starting index of the subsequence, that has the smallest distance to it. If you imagine the subsequences being points in a <span class="math inline">\(m\)</span> dimensional Space, then the matrix profile index of a subsequence is the starting index of the closest neighbor and the matrix profile value is the distance to the closest neighbor.</p>
<figure>
<img src="images/MP_example.png" alt="" /><figcaption>Example of the matrix profile on the steamgen dataset.</figcaption>
</figure>
<p>So, what does this tell us? In the example above you can see a visualization of the Matrix Profile for the <a href="https://www.cs.ucr.edu/~eamonn/iSAX/steamgen.dat">Steamgen Dataset</a>. In the upper plot you see the data set, and in the lower plot you see a plot of the Matrix Profile. The two dashed lines represent the lowest values in the Matrix Profile. This means the two subsequences that start at each of these lines have a very small (the smallest) distance from each other, hence they are very similar. This means, that by visually inspecting the Matrix Profile we can immediately see the most repeated pattern. There are various other things to discover and better overview can be found on the UCR page <span class="citation" data-cites="Keogh:UCRMatrixProfile">(Keogh, n.d.)</span>. There exist also generalizations to more dimensions, see <span class="citation" data-cites="Yeh:MatrixProfileVI">(Yeh, Kavantzas, and Keogh 2017b)</span>.</p>
<p>There exists a very good Python library called <em>stumpy</em> for computing the Matrix Profile that also has very good support by the author. The Github page can be found here <span class="citation" data-cites="Law:stumpy">(Law 2019)</span>.</p>
<h3 id="how-could-the-mp-be-used">How could the MP be used?</h3>
<p>As described above, the MP profile is a tool that can help to discover repeating or anomalous patterns in time series data. Hence we can aim to apply it to any of the many time series produced by the source.</p>
<ol type="1">
<li>Patterns in the BCT currents for prediction: One could try to discover repeating patterns in the BCT currents and see if they can be used to predict the future development. For example if a pattern indicates a degradation of the current in the near future, it could be used to alert the operators in time. There exists also a real time version of the MP, where it gets updated with every arriving data point. For this the SDTS algorithm <span class="citation" data-cites="Yeh:MatrixProfileIV">(Yeh, Kavantzas, and Keogh 2017a)</span> built on top of the MP could be interesting.</li>
<li>Pattern in the BCT current for analysis: Likewise, one could try to link patterns in the BCT with patterns/actions of other parameters. For example, often times a slow increase of the HT current leads to a slow degradation of the BCT current.</li>
<li>Motifs of different parameter combinations shifted in time: When computing the multidimensional matrix profile, to see if there are motifs in more than on dimension, one could shift one of the time series in time, to see for example how a change of the gas voltage affects the current in one hour.</li>
<li>Meta time series: Instead of looking at the original time series, one could try to look for motifs or discords in a rolling window time series. For example, one could calculate the standard deviation in one hour windows over the BCT25 current and look for repeated patterns there, to maybe find motifs that will indicate a future unstable period.</li>
</ol>
<h3 id="difficulties">Difficulties</h3>
<p>The MP is built under the assumption, that repeated patterns or motifs are an effect of a regular event in the generating process. One example from the Papers is Seismology. There the time series is the recording of a Seismograph, which can have very long periods of “random” data, where nothing happens. However, an earthquake would show up with a very distinctive shape.</p>
<figure>
<img src="images/current_demo.png" alt="" /><figcaption>Example of the BCT25 current</figcaption>
</figure>
<figure>
<img src="images/current_demo_2.png" alt="" /><figcaption>Example of the BCT25 current, smaller window</figcaption>
</figure>
<p>In our case however, the BCT signals are mostly flat with oscillations (see the two images above), hence motif discovery with z-normalized subsequences is very insufficient. If you have two flat signals with a lot of added noise, their z-normalized euclidean distance will be very large, even if one might expect it to be small because visually they are very similar. There are some ideas to mitigate the problem <span class="citation" data-cites="Paepe:EliminatingNoiseMatrix">(Paepe, Janssens, and Hoecke 2019)</span>, but I didn’t get any satisfying results.</p>
<h3 id="results">Results</h3>
<p>Instead of trying to use a matrix profile with removed noise I flattened the signal over some minutes and found several links of parameter changes to BCT current. The results where achieved using the MSTOMP algorithm <span class="citation" data-cites="Yeh:MatrixProfileVI">(Yeh, Kavantzas, and Keogh 2017b)</span>, a multi dimensional generalisation of the matrix profile calculation.</p>
<figure>
<img src="images/hti_bct_htirise.png" alt="" /><figcaption>Rise of HTI (bottom) and degradation of BCT25 current (top).</figcaption>
</figure>
<p>A rising HTI often coincides with a degrading BCT25 current, so this seems to confirm this theory. However it is not a proof that an opposite effect (e.g. rising HTI and rising BCT current) doesn’t also exist. But we didn’t observe it in the time frame we considered (August and September 2016).</p>
<figure>
<img src="images/hti_bct_htifall.png" alt="" /><figcaption>Drops of the HTI and jumps in the BCT25 current.</figcaption>
</figure>
<p>The reverse can also be seen. Drops of the HTI correlate with jumps in the BCT25 current.</p>
<figure>
<img src="images/bct_oven_hti.png" alt="" /><figcaption>A common pattern when including BCT25 current, HTI and Oven1 power.</figcaption>
</figure>
<p>One possible explanation we explored is that the behavior in the second image can often time be achieved by increasing the Oven Power. This can be seen in this image.</p>
<figure>
<img src="images/bct_oven_hti_2dim.png" alt="" /><figcaption>Jumps in BCT25 current and HTI without changes of the Oven power.</figcaption>
</figure>
<p>However, it appears that there are cases where the oven remains unchanged. Further invastigation is necessary, but it could be that the power of Oven 2 was increased, as this is only the data for Oven 1.</p>
<figure>
<img src="images/gas_oven_hti.png" alt="" /><figcaption>Correlation of gas voltage decreases with oven power increases.</figcaption>
</figure>
<p>We could also see that an increase of the oven power is often accompanied with a decrease of the gas voltage.</p>
<p>We didn’t see any meaningful motifs when jointly looking at the Bias Disc Voltage and the BCT25 current.</p>
<h2 id="discretization">Discretization</h2>
<p>One problem of using the data from CALS/NXCALS is that for all setting only acquisitions are logged. This means, that we typically don’t know the exact values a setting was changed to, see the figure below for example. It shows one day (05.11.2018) of Oven1 power acquisition from NXCALS, where only one data point every five minutes is logged. From the logbook we can learn that at 14:00 the Oven1 Power was set to 12.0W, however on the plot we can see some oscillations (The times in the plot are UTC, so you have to count +2h).</p>
<p><img src="images/oven1example_05112018.png" /></p>
<figure>
<img src="images/oven1example_logbook_05112018.png" alt="" /><figcaption>Top: Screenshot of Oven1 Acquisition, Bottom: The real value that was set at 14:00.</figcaption>
</figure>
<p>The same occurs with other settings, and raises the problem that we cannot directly say when a change of a certain setting happened. So I tried to discretize the raw acquisition values and get back the true setting where possible. The main assumption I had to make is that a setting remained constant over time, unless somebody changes it. This appears reasonable in most cases, but in some extreme cases some information might be lost (see below).</p>
<figure>
<img src="images/gas_example_02112018.png" alt="" /><figcaption>GASAQN voltage on the second and third November 2018. This was during an oven refill where the gas pressure changes not as a step function.</figcaption>
</figure>
<p>Under this assumption we can model a setting as a step function <span class="citation" data-cites="Weisstein:StepFunction">(Weisstein, n.d.)</span> with added noise, and the problem is to find the step function. I will call the step function <em>discretization</em>, because we separate our time series into discrete states of a fixed setting.</p>
<p>There are several techniques that could be used to solve such a problem, and we will discuss some of them <a href="#change-point-detection">below</a> in more detail for a different use case. For this use case I combined a simple rolling window approach with a decision tree regressor. Some results can be seen below.</p>
<figure>
<img src="images/oven_discrete_nov2016.png" alt="" /><figcaption>Discretization of Oven Power for November 2016. In blue the original data is plotted, the orange line represents the discrete approximation.</figcaption>
</figure>
<figure>
<img src="images/rf_discrete_nov2016.png" alt="" /><figcaption>Discretization of RF Power for November 2016.</figcaption>
</figure>
<p>As one can see, the discrete approximation, our attempt at finding the true step function, follows the acquisition signal very closely and most changes are modeled correctly. This can also be seen when comparing the results with entries in the elogbook (especially for the oven, since here most changes are noted in the logbook). As can be seen in the figures, during some periods no discrete approximation is plotted. This is the case when the source was off (BCT05 current 0A), because the method does not work well when there are sections with a non-step function like signal as during an oven restart, so I cut them out.</p>
<h3 id="explanation">Explanation</h3>
<p>As described above, the process involves using a Decision Tree Regressor. A decision tree partitions the input data by sequentially applying if-then-else rules. It can be thought of as a directed graph, were every node is one of these rules. End nodes, so called leaves, that return the class the input is belonging to. Training a decision tree means finding an optimal set of rules, that explains the training data as good as possible. [TODO: Add reference]. Decision trees are a supervised learning method, meaning that for each training input a output class is specified, and the algorithm tries to learn this relationship.</p>
<p>Decision trees can be used for regression. If you want to regress a function <span class="math inline">\(\mathbb R^n \to \mathbb R; \quad (x_1, \dots, x_n) \mapsto y\)</span> you pass <span class="math inline">\((x_1, \dots, x_n)\)</span> as input and <span class="math inline">\(y\)</span> as the desired class. In the case of an one dimensional function for example, a decision tree classifier could lern that for <span class="math inline">\(x&gt;=5\)</span> and <span class="math inline">\(x&lt;=10\)</span> it should output <span class="math inline">\(y=5\)</span>. So, by the nature of a decision tree, the regression result is a step function, that looks like the result as much as possible.</p>
<p>One very common problem with decision trees is over fitting. If they are allowed to grow too much, they are not regressing any more, but copying. For example suppose that all your input data points are the natural numbers. By building a tree with the rules <span class="math inline">\((x &gt;= 0.5, x &lt;1.5)\)</span>, <span class="math inline">\((x &gt;= 1.5, x &lt;2.5)\)</span>, <span class="math inline">\((x &gt;= 2.5, x &lt;3.5)\)</span>, … the resulting regressor could perfectly replicate the input function, but it would learn all small oscillations, what is not what we are typically interested in. However, one thing that can be controlled is how many leaf nodes the tree can have, i.e. in the 1D case into how many intervals the real axis can be split at most.</p>
<p>In our case it would hence be useful to know how many discrete levels, or number of constant segments, the function we want to model consist of. Then, we could regress it using a tree with this maximum of leaf node, because by minimizing the error (i.e. difference from the original function) it would find the best stepwise approximation to the input data without over-fitting.</p>
<h4 id="finding-the-number-of-constant-segments">Finding the number of constant segments</h4>
<h2 id="change-point-detection">Change Point Detection</h2>
<h2 id="suffix-arrays">Suffix arrays</h2>
<h2 class="unnumbered" id="references">References</h2>
<div id="refs" class="references hanging-indent" role="doc-bibliography">
<div id="ref-Hinneburg:OptimalGridClustering">
<p>Hinneburg, A., and D. A. Keim. 1999. “Optimal Grid-Clustering: Towards Breaking the Curse of Dimensionality in High-Dimensional Clustering.” <em>Proceedings of the 25th International Conference on Very Large Databases</em>, 506–17. <a href="https://kops.uni-konstanz.de/bitstream/handle/123456789/5790/vldb99.pdf">https://kops.uni-konstanz.de/bitstream/handle/123456789/5790/vldb99.pdf</a>.</p>
</div>
<div id="ref-Keogh:UCRMatrixProfile">
<p>Keogh, Eamonn. n.d. “The Ucr Matrix Profile Page.” <a href="https://www.cs.ucr.edu/~eamonn/MatrixProfile.html">https://www.cs.ucr.edu/~eamonn/MatrixProfile.html</a>.</p>
</div>
<div id="ref-Law:stumpy">
<p>Law, Sean M. 2019. “STUMPY: A Powerful and Scalable Python Library for Time Series Data Mining.” <em>The Journal of Open Source Software</em> 4 (39): 1504. <a href="https://github.com/TDAmeritrade/stumpy/">https://github.com/TDAmeritrade/stumpy/</a>.</p>
</div>
<div id="ref-Paepe:EliminatingNoiseMatrix">
<p>Paepe, Dieter De, Olivier Janssens, and Sofie Van Hoecke. 2019. “Eliminating Noise in the Matrix Profile.” In <em>ICPRAM</em>. <a href="https://biblio.ugent.be/publication/8605188/file/8605190.pdf">https://biblio.ugent.be/publication/8605188/file/8605190.pdf</a>.</p>
</div>
<div id="ref-Weisstein:StepFunction">
<p>Weisstein, Eric W. n.d. “Step Function.” From MathWorld–A Wolfram Web Resource. <a href="https://mathworld.wolfram.com/StepFunction.html">https://mathworld.wolfram.com/StepFunction.html</a>.</p>
</div>
<div id="ref-Yeh:MatrixProfileIV">
<p>Yeh, Chin-Chia Michael, Nickolas Kavantzas, and Eamonn Keogh. 2017a. “Matrix Profile Iv: Using Weakly Labeled Time Series to Predict Outcomes.” <em>VLDB 2017</em>. <a href="https://www.cs.ucr.edu/~eamonn/WeaklyLabeledTimeSeries.pdf">https://www.cs.ucr.edu/~eamonn/WeaklyLabeledTimeSeries.pdf</a>.</p>
</div>
<div id="ref-Yeh:MatrixProfileVI">
<p>———. 2017b. “Matrix Profile Vi: Meaningful Multidimensional Motif Discovery.” <em>ICDM 2017</em>. <a href="http://www.cs.ucr.edu/%7Eeamonn/Motif_Discovery_ICDM.pdf">http://www.cs.ucr.edu/%7Eeamonn/Motif_Discovery_ICDM.pdf</a>.</p>
</div>
<div id="ref-Yeh:MatrixProfileI">
<p>Yeh, Chin-Chia Michael, Yan Zhu, Liudmila Ulanova, Nurjahan Begum, Yifei Ding, Hoang Anh Dau, Diego Furtado Silva, Abdullah Mueen, and Eamonn Keogh. 2016. “Matrix Profile I: All Pairs Similarity Joins for Time Series: A Unifying View That Includes Motifs, Discords and Shapelets.” <em>IEEE ICDM 2016</em>. <a href="https://www.cs.ucr.edu/~eamonn/PID4481997_extend_Matrix%20Profile_I.pdf">https://www.cs.ucr.edu/~eamonn/PID4481997_extend_Matrix%20Profile_I.pdf</a>.</p>
</div>
</div>
</body>
</html>
